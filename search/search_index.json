{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome","title":"Welcome \ud83d\udc4b","text":"<p><code>mf2py</code> is a Python microformats parser with full support for <code>microformats2</code>, backwards-compatible support for <code>microformats1</code> and experimental support for <code>metaformats</code>.</p>"},{"location":"#installation","title":"Installation \ud83d\udcbb","text":"<p>To install <code>mf2py</code> run the following command:</p> <pre><code>$ pip install mf2py\n</code></pre>"},{"location":"#quickstart","title":"Quickstart \ud83d\ude80","text":"<p>Import the library:</p> <pre><code>&gt;&gt;&gt; import mf2py\n</code></pre>"},{"location":"#parse-an-html-document-from-a-file-or-string","title":"Parse an HTML Document from a file or string","text":"<pre><code>&gt;&gt;&gt; with open(\"test/examples/eras.html\") as fp:\n...     mf2json = mf2py.parse(doc=fp)\n&gt;&gt;&gt; mf2json\n{'items': [{'type': ['h-entry'],\n            'properties': {'name': ['Excited for the Taylor Swift Eras Tour'],\n                           'author': [{'type': ['h-card'],\n                                       'properties': {'name': ['James'],\n                                                      'url': ['https://example.com/']},\n                                       'value': 'James',\n                                       'lang': 'en-us'}],\n                           'published': ['2023-11-30T19:08:09'],\n                           'featured': [{'value': 'https://example.com/eras.jpg',\n                                         'alt': 'Eras tour poster'}],\n                           'content': [{'value': \"I can't decide which era is my favorite.\",\n                                        'lang': 'en-us',\n                                        'html': \"&lt;p&gt;I can't decide which era is my favorite.&lt;/p&gt;\"}],\n                           'category': ['music', 'Taylor Swift']},\n            'lang': 'en-us'}],\n 'rels': {'webmention': ['https://example.com/mentions']},\n 'rel-urls': {'https://example.com/mentions': {'text': '',\n                                               'rels': ['webmention']}},\n 'debug': {'description': 'mf2py - microformats2 parser for python',\n           'source': 'https://github.com/microformats/mf2py',\n           'version': '2.0.0',\n           'markup parser': 'html5lib'}}\n</code></pre> <pre><code>&gt;&gt;&gt; mf2json = mf2py.parse(doc=\"&lt;a class=h-card href=https://example.com&gt;James&lt;/a&gt;\")\n&gt;&gt;&gt; mf2json[\"items\"]\n[{'type': ['h-card'],\n  'properties': {'name': ['James'],\n                 'url': ['https://example.com']}}]\n</code></pre>"},{"location":"#parse-an-html-document-from-a-url","title":"Parse an HTML Document from a URL","text":"<pre><code>&gt;&gt;&gt; mf2json = mf2py.parse(url=\"https://events.indieweb.org\")\n&gt;&gt;&gt; mf2json[\"items\"][0][\"type\"]\n['h-feed']\n&gt;&gt;&gt; mf2json[\"items\"][0][\"children\"][0][\"type\"]\n['h-event']\n</code></pre>"},{"location":"#experimental-options","title":"Experimental Options","text":"<p>The following options can be invoked via keyword arguments to <code>parse()</code> and <code>Parser()</code>.</p>"},{"location":"#expose_dom","title":"<code>expose_dom</code>","text":"<p>Use <code>expose_dom=True</code> to expose the DOM of embedded properties.</p>"},{"location":"#metaformats","title":"<code>metaformats</code>","text":"<p>Use <code>metaformats=True</code> to include any metaformats found.</p>"},{"location":"#filter_roots","title":"<code>filter_roots</code>","text":"<p>Use <code>filter_roots=True</code> to filter known conflicting user names (e.g. Tailwind). Otherwise provide a custom list to filter instead.</p>"},{"location":"#advanced-usage","title":"Advanced Usage","text":"<p><code>parse</code> is a convenience function for <code>Parser</code>. More sophisticated behaviors are available by invoking the parser object directly.</p> <pre><code>&gt;&gt;&gt; with open(\"test/examples/festivus.html\") as fp:\n...     mf2parser = mf2py.Parser(doc=fp)\n</code></pre>"},{"location":"#filter-by-microformat-type","title":"Filter by Microformat Type","text":"<pre><code>&gt;&gt;&gt; mf2json = mf2parser.to_dict()\n&gt;&gt;&gt; len(mf2json[\"items\"])\n7\n&gt;&gt;&gt; len(mf2parser.to_dict(filter_by_type=\"h-card\"))\n3\n&gt;&gt;&gt; len(mf2parser.to_dict(filter_by_type=\"h-entry\"))\n4\n</code></pre>"},{"location":"#json-output","title":"JSON Output","text":"<pre><code>&gt;&gt;&gt; json = mf2parser.to_json()\n&gt;&gt;&gt; json_cards = mf2parser.to_json(filter_by_type=\"h-card\")\n</code></pre>"},{"location":"#breaking-changes-in-mf2py-20","title":"Breaking Changes in <code>mf2py</code> 2.0","text":"<ul> <li>Image <code>alt</code> support is now on by default.</li> </ul>"},{"location":"#notes","title":"Notes \ud83d\udcdd","text":"<ul> <li>If you pass a BeautifulSoup document it may be modified.</li> <li>A hosted version of <code>mf2py</code> is available at python.microformats.io.</li> </ul>"},{"location":"#contributing","title":"Contributing \ud83d\udee0\ufe0f","text":"<p>We welcome contributions and bug reports via GitHub.</p> <p>This project follows the IndieWeb code of conduct. Please be respectful of other contributors and forge a spirit of positive co-operation without discrimination or disrespect.</p>"},{"location":"#license","title":"License \ud83e\uddd1\u200d\u2696\ufe0f","text":"<p><code>mf2py</code> is licensed under an MIT License.</p>"},{"location":"changelog/","title":"Change Log","text":"<p>All notable changes to this project will be documented in this file.</p>"},{"location":"changelog/#200-2023-12-07","title":"2.0.0 - 2023-12-07","text":"<p>The mf2py library is excited to transition into 2.0. This version increase incorporates months of work from contributors, informed by active discussions among implementers and users.</p> <p>This release officially deprecates support for versions of Python lower than 3.8.</p> <p>Below are the changes we have made in this release.</p>"},{"location":"changelog/#new-features","title":"New Features","text":"<ul> <li>Enable <code>img_with_alt</code> by default (#184)</li> <li>Add timezone offset normalisation (#206)</li> <li>Add option for exposing DOM for embedded properties (#208)</li> <li>Add srcset support (#209)</li> <li>Add language support (#210)</li> <li>Add option for filtering root class names (#211)</li> <li>Add option for metaformats support (#213)</li> </ul>"},{"location":"changelog/#changes","title":"Changes","text":"<ul> <li>Remove <code>img_with_alt</code> option entirely (#200)</li> <li>Resolve implied photo relative paths (#205)</li> <li>Make relative URLs in embedded properties absolute (#201)</li> <li>Fix whitespace in plaintext conversion (#207)</li> <li>Replace <code>dict_class</code> with standard <code>dict</code> (#196)</li> </ul>"},{"location":"changelog/#tests-library-and-documentation-maintenance","title":"Tests, Library and Documentation Maintenance","text":"<ul> <li>Update tests to include alt texts by default (#190)</li> <li>Add Windows and macOS tests (#198)</li> <li>Use poetry for dependency management (#189)</li> <li>Deprecate Python 2 support (#179)</li> <li>Lint code with <code>black</code> and <code>isort</code></li> <li>Add linting CI actions (#193)</li> <li>Move from <code>nosetests</code> to <code>pytest</code> (#186)</li> <li>Add 3.11, 3.12 and drop pypy from test matrix; upgrade poetry action (#204)</li> <li>Prepare tests to test options (#214)</li> <li>Bring README doctests up-to-date (#215)</li> </ul>"},{"location":"changelog/#113-2022-06-28","title":"1.1.3 - 2022-06-28","text":"<ul> <li>reduce instances where photo is implied (#135)</li> <li>always do relative URL resolution (#138)</li> <li>VCP now handles tz offsets without leading zeros (#142)</li> <li>implement id parsing (#143)</li> <li>fix outdated syntax causing SyntaxWarning (#157)</li> </ul>"},{"location":"changelog/#112-2018-08-08","title":"1.1.2 - 2018-08-08","text":"<ul> <li>add parsing for iframe.u-*[src] (#116)</li> <li>bug fix: reduced implied urls (#117)</li> <li>bug fix: don't collapse whitespace between tags</li> <li>specify explicit versions for dependencies</li> <li>revert BeautifulSoup copying added in 1.1.1 due to bugs (eg #108)</li> <li>misc performance improvements</li> </ul>"},{"location":"changelog/#111-2018-06-15","title":"1.1.1 - 2018-06-15","text":"<ul> <li>streamline backcompat to use JSON only.</li> <li>fix multiple mf1 root rel-tag parsing</li> <li>correct url and photo for hreview.</li> <li>add rules for nested hreview. update backcompat to use multiple matches in old properties.</li> <li>fix <code>rel-tag</code> to <code>p-category</code> conversion so that other classes are not lost.</li> <li>use original authored html for <code>e-*</code> parsing in backcompat</li> <li>make classes and rels into unordered (alphabetically ordered) deduped arrays.</li> <li>only use class names for mf2 which follow the naming rules</li> <li>fix <code>parse</code> method to use default html parser.</li> <li>always use the first value for attributes for rels.</li> <li>correct AM/PM conversion in datetime value class pattern.</li> <li>add ordinal date parsing to datetimes value class pattern. ordinal date is normalised to YYYY-MM-DD</li> <li>remove hack for html tag classes since that is fixed in new BS</li> <li>better whitespace algorithm for <code>name</code> and <code>html.value</code> parsing</li> <li>experimental flag for including <code>alt</code> in <code>u-photo</code> parsing</li> <li>make a copy of the BeautifulSoup given by user to work on for parsing to prevent changes to original doc</li> <li>bump version to 1.1.1</li> </ul>"},{"location":"changelog/#110-2018-03-16","title":"1.1.0 - 2018-03-16","text":"<ul> <li>bump version to 1.1.0 since it is a \"major\" change</li> <li>added tests for new implied name rules</li> <li>modified earlier tests to accommodate new rules</li> <li>use space separator instead of \"T\"</li> <li>Don't add \"00\" seconds unless authored</li> <li>use TZ authored in separate <code>value</code> element</li> <li>only use first found <code>value</code> of a particular type <code>date</code>, <code>time</code>, or <code>timezone</code>.</li> <li>move backcompat rules into JSON files</li> <li>reorganise value class pattern parsing into new files</li> <li>add datetime_helpers to organise datetime parsing rules</li> <li>reorganise tests</li> <li>remove Heroku frontend, point to mf2py-web and python.microformats.io instead in README.</li> <li>remove Flask and gunicorn requirements</li> <li>add debug info with description, version, url and the html parser used</li> </ul>"},{"location":"changelog/#106-2018-03-04","title":"1.0.6 - 2018-03-04","text":"<ul> <li>strip leading/trailing white space for <code>e-*[html]</code>. update the corresponding tests</li> <li>blank values explicitly authored are allowed as property values</li> <li>include <code>alt</code> or <code>src</code> from <code>&lt;img&gt;</code> in parsing for <code>p-*</code> and <code>e-*[value]</code></li> <li>parse <code>title</code> from <code>&lt;link&gt;</code> for <code>p-*</code> resolves #84</li> <li>and <code>poster</code> from <code>&lt;video&gt;</code> for <code>u-*</code> resolves #76</li> <li>use <code>html5lib</code> as default parser</li> <li>use the final redirect URL resolves #62</li> <li>update requirements to use BS4 v4.6.0 and html5lib v1.0.1</li> <li>drop support for Python 2.6 as html5lib dropped support</li> </ul>"},{"location":"changelog/#105-2016-05-09","title":"1.0.5 - 2016-05-09","text":"<ul> <li>Implied property checks now ignore alt=\"\", treating it the same as   if no alt value is defined.</li> <li>Support for using a custom dict implementation by setting   mf2py.Parser.dict_class. collections.OrderedDict yields much nicer   output for hosted parsers.</li> </ul>"},{"location":"changelog/#104-2016-03-21","title":"1.0.4 - 2016-03-21","text":"<ul> <li>Performance improvement changing simple calls to soup.find_all to   a manual iteration over .contents.</li> </ul>"},{"location":"changelog/#103-2016-02-05","title":"1.0.3 - 2016-02-05","text":"<ul> <li>Performance improvement by limiting number of calls to soup.find_all   in backcompat module. Should not be any functional changes.</li> </ul>"},{"location":"changelog/#102-2016-01-26","title":"1.0.2 - 2016-01-26","text":"<ul> <li>Backward compatibility parsing for rel=tag properties. These are now converted   to p-category based on the last path segment of the tag URI as spec'd in   http://microformats.org/wiki/h-entry#Parser_Compatibility</li> <li>Optional property html_parser to specify the html parser that BeautifulSoup   should use (e.g., \"lxml\" or \"html5lib\")</li> </ul>"},{"location":"changelog/#101-2015-12-11","title":"1.0.1 - 2015-12-11","text":"<ul> <li><code>u-*</code> properties are now parsed from <code>&lt;link&gt;</code> elements per the updated spec   http://microformats.org/wiki/microformats2-parsing-issues#link_elements_and_u-_parsing</li> </ul>"},{"location":"changelog/#100-2015-10-05","title":"1.0.0 - 2015-10-05","text":"<ul> <li>Version number bumped to 1.0.0 following community discussion.</li> </ul>"},{"location":"changelog/#028-2015-09-21","title":"0.2.8 - 2015-09-21","text":"<ul> <li>Stricter checks that Parser.init params are actually None before   ignoring them.</li> </ul>"},{"location":"changelog/#027-2015-08-03","title":"0.2.7 - 2015-08-03","text":"<ul> <li>Now produces unicode strings for every key and value, no more byte   strings anywhere.</li> <li>Do not add 'T' between date and time when normalizing dates</li> <li>Unit tests for running the microformats test suite</li> </ul>"},{"location":"changelog/#026-2015-05-06","title":"0.2.6 - 2015-05-06","text":"<ul> <li>New top-level \"rel-urls\" entry, contains rich data parsed from rel   links, organized by URL.</li> </ul>"},{"location":"changelog/#025-2015-03-01","title":"0.2.5 - 2015-03-01","text":"<ul> <li>convenience method <code>mf2py.parse</code> that takes the same arguments as Parser   and returns a dict.</li> <li>nested h- classes now parse their \"value\" based on the property   they represent (p-, u-, dt-), so for example \"p-in-reply-to   h-cite\" would have a name as its value and \"u-in-reply-to h-cite\"   will have a URL.</li> </ul>"},{"location":"changelog/#024-2015-02-13","title":"0.2.4 - 2015-02-13","text":"<ul> <li>Add rel=bookmark to backward compat parsing rules based (translated   to u-url in mf2)</li> <li>Parser constructor now takes explicit named arguments instead of   **kwargs, for saner behavior when called with unnamed arguments.</li> <li>Bugfix: Empty href=\"\" attributes are now properly interpreted as   the current document's URL.</li> </ul>"},{"location":"changelog/#023-2015-02-07","title":"0.2.3 - 2015-02-07","text":"<ul> <li>Minor Py3 compatibility fix</li> <li>Correct typo <code>test_requires</code> -&gt; <code>tests_require</code> in setup.py</li> </ul>"},{"location":"changelog/#022-2015-02-05","title":"0.2.2 - 2015-02-05","text":"<ul> <li>Started keeping a changelog!</li> <li>Use a better method for extracting HTML for an e-* property</li> <li>Correct BeautifulSoup4 dependency in setup.py to fix error with   installation from PyPI.</li> <li>Buffed up docstrings for public methods.</li> </ul>"},{"location":"parser/","title":"Parser Object","text":"<p>             Bases: <code>object</code></p> <p>Parser to parse a document or URL for microformats and output in various formats.</p> <p>Parameters:</p> Name Type Description Default <code>doc</code> <code>file, string or BeautifulSoup doc</code> <p>file handle, text of content to parse, or BeautifulSoup document. If None it will be fetched from given URL.</p> <code>None</code> <code>url</code> <code>string</code> <p>URL of the file to be processed. If None it will be extracted from the <code>&lt;base&gt;</code> element of given doc.</p> <code>None</code> <code>html_parser</code> <code>string</code> <p>optional, select a specific HTML parser. Valid options from the BeautifulSoup documentation are: \"html\", \"xml\",\"html5\", \"lxml\", \"html5lib\", and \"html.parser\".</p> <code>None</code> <code>expose_dom</code> <code>boolean</code> <p>optional, expose the DOM of embedded properties.</p> <code>False</code> <code>metaformats</code> <code>boolean</code> <p>optional, include metaformats extracted from OGP and Twitter card data: https://microformats.org/wiki/metaformats</p> <code>False</code> <code>filter_roots</code> <code>boolean or list</code> <p>optional, filter root class names. Use True to filter known conflicting classes, otherwise filter given list.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>useragent</code> <code>string</code> <p>the User-Agent string for the Parser</p> Source code in <code>mf2py/parser.py</code> <pre><code>class Parser(object):\n    \"\"\"\n    Parser to parse a document or URL for microformats and output in various formats.\n\n    Args:\n      doc (file, string or BeautifulSoup doc): file handle, text of content\n        to parse, or BeautifulSoup document. If None it will be fetched from\n        given URL.\n      url (string): URL of the file to be processed. If None it will be\n        extracted from the `&lt;base&gt;` element of given doc.\n      html_parser (string): optional, select a specific HTML parser. Valid options\n        from the BeautifulSoup documentation are: \"html\", \"xml\",\"html5\", \"lxml\",\n        \"html5lib\", and \"html.parser\".\n      expose_dom (boolean): optional, expose the DOM of embedded properties.\n      metaformats (boolean): optional, include metaformats extracted from OGP\n        and Twitter card data: https://microformats.org/wiki/metaformats\n      filter_roots (boolean or list): optional, filter root class names. Use\n        True to filter known conflicting classes, otherwise filter given list.\n\n    Attributes:\n      useragent (string): the User-Agent string for the Parser\n\n    \"\"\"\n\n    ua_desc = \"mf2py - microformats2 parser for python\"\n    ua_url = \"https://github.com/microformats/mf2py\"\n    useragent = \"{0} - version {1} - {2}\".format(ua_desc, __version__, ua_url)\n\n    def __init__(\n        self,\n        doc=None,\n        url=None,\n        html_parser=None,\n        expose_dom=False,\n        metaformats=False,\n        filter_roots=False,\n    ):\n        self.__url__ = None\n        self.__doc__ = None\n        self._preserve_doc = False\n        self.__parsed__ = {\n            \"items\": [],\n            \"rels\": {},\n            \"rel-urls\": {},\n            \"debug\": {\n                \"description\": self.ua_desc,\n                \"source\": self.ua_url,\n                \"version\": __version__,\n            },\n        }\n        self.lang = None\n        self.expose_dom = expose_dom\n        self.__metaformats = metaformats\n        try:\n            self.filtered_roots = set(filter_roots)\n        except TypeError:\n            if filter_roots:\n                self.filtered_roots = mf2_classes.CONFLICTING_ROOTS_TAILWIND\n            else:\n                self.filtered_roots = []\n\n        # use default parser if none specified\n        self.__html_parser__ = html_parser or \"html5lib\"\n\n        if url is not None:\n            self.__url__ = url\n\n            if doc is None:\n                data = requests.get(\n                    self.__url__,\n                    headers={\n                        \"User-Agent\": self.useragent,\n                    },\n                )\n\n                # update to final URL after redirects\n                self.__url__ = data.url\n\n                # HACK: check for character encodings and use 'correct' data\n                if \"charset\" in data.headers.get(\"content-type\", \"\"):\n                    doc = data.text\n                else:\n                    doc = data.content\n\n        if doc is not None:\n            if isinstance(doc, BeautifulSoup) or isinstance(doc, Tag):\n                self.__doc__ = doc\n                self._preserve_doc = True\n            else:\n                try:\n                    # try the user-given html parser or default html5lib\n                    self.__doc__ = BeautifulSoup(doc, features=self.__html_parser__)\n                except FeatureNotFound:\n                    # maybe raise a warning?\n                    # else switch to default use\n                    self.__doc__ = BeautifulSoup(doc)\n\n        # update actual parser used\n        # uses builder.NAME from BeautifulSoup\n        if isinstance(self.__doc__, BeautifulSoup) and self.__doc__.builder is not None:\n            self.__html_parser__ = self.__doc__.builder.NAME\n        else:\n            self.__html_parser__ = None\n\n        # check for &lt;base&gt; tag\n        if self.__doc__:\n            poss_base = next(\n                (el for el in get_descendents(self.__doc__) if el.name == \"base\"), None\n            )\n            if poss_base:\n                poss_base_url = poss_base.get(\"href\")  # try to get href\n                if poss_base_url:\n                    if urlparse(poss_base_url).netloc:\n                        # base specifies an absolute path\n                        self.__url__ = poss_base_url\n                    elif self.__url__:\n                        # base specifies a relative path\n                        self.__url__ = try_urljoin(self.__url__, poss_base_url)\n\n        if self.__doc__ is not None:\n            if document := self.__doc__.find(\"html\"):\n                self.lang = document.attrs.get(\"lang\")\n            # parse!\n            self._parse()\n\n    def _parse(self):\n        \"\"\"Does the work of actually parsing the document. Done automatically\n        on initialization.\n        \"\"\"\n        self._default_date = None\n        # _default_date exists to provide implementation for rules described\n        # in legacy value-class-pattern. basically, if you have two dt-\n        # properties and one does not have the full date, it can use the\n        # existing date as a template.\n        # see value-class-pattern#microformats2_parsers on wiki.\n        # see also the implied_relative_datetimes testcase.\n\n        def handle_microformat(\n            root_class_names,\n            el,\n            value_property=None,\n            simple_value=None,\n            backcompat_mode=False,\n        ):\n            \"\"\"Handles a (possibly nested) microformat, i.e. h-*\"\"\"\n            properties = {}\n            children = []\n            self._default_date = None\n            # for processing implied properties: collects if property types (p, e, u, d(t)) or children (h) have been processed\n            parsed_types_aggregation = set()\n\n            if backcompat_mode:\n                el = backcompat.apply_rules(\n                    el, self.__html_parser__, self.filtered_roots\n                )\n                root_class_names = mf2_classes.root(\n                    el.get(\"class\", []), self.filtered_roots\n                )\n\n            root_lang = el.attrs.get(\"lang\")\n\n            # parse for properties and children\n            for child in get_children(el):\n                (\n                    child_props,\n                    child_children,\n                    child_parsed_types_aggregation,\n                ) = parse_props(child, root_lang)\n                for key, new_value in child_props.items():\n                    prop_value = properties.get(key, [])\n                    prop_value.extend(new_value)\n                    properties[key] = prop_value\n                children.extend(child_children)\n                parsed_types_aggregation.update(child_parsed_types_aggregation)\n\n            # complex h-* objects can take their \"value\" from the\n            # first explicit property (\"name\" for p-* or \"url\" for u-*)\n            if value_property and value_property in properties:\n                simple_value = properties[value_property][0]\n\n            # if some properties not already found find in implied ways unless in backcompat mode\n            if not backcompat_mode:\n                # stop implied name if any p-*, e-*, h-* is already found\n                if \"name\" not in properties and parsed_types_aggregation.isdisjoint(\n                    \"peh\"\n                ):\n                    properties[\"name\"] = [\n                        implied_properties.name(el, self.__url__, self.filtered_roots)\n                    ]\n\n                if \"photo\" not in properties and parsed_types_aggregation.isdisjoint(\n                    \"uh\"\n                ):\n                    x = implied_properties.photo(el, self.__url__, self.filtered_roots)\n                    if x is not None:\n                        properties[\"photo\"] = [x]\n\n                # stop implied url if any u-* or h-* is already found\n                if \"url\" not in properties and parsed_types_aggregation.isdisjoint(\n                    \"uh\"\n                ):\n                    x = implied_properties.url(el, self.__url__, self.filtered_roots)\n                    if x is not None:\n                        properties[\"url\"] = [x]\n\n            # build microformat with type and properties\n            microformat = {\n                \"type\": [class_name for class_name in sorted(root_class_names)],\n                \"properties\": properties,\n            }\n            if el.name == \"area\":\n                shape = get_attr(el, \"shape\")\n                if shape is not None:\n                    microformat[\"shape\"] = shape\n\n                coords = get_attr(el, \"coords\")\n                if coords is not None:\n                    microformat[\"coords\"] = coords\n\n            # insert children if any\n            if children:\n                microformat[\"children\"] = children\n\n            Id = get_attr(el, \"id\")\n            if Id:\n                microformat[\"id\"] = Id\n\n            # simple value is the parsed property value if it were not\n            # an h-* class\n            if simple_value is not None:\n                if isinstance(simple_value, dict):\n                    # for e-* properties, the simple value will be\n                    # {\"html\":..., \"value\":...}  which we should fold\n                    # into the microformat object\n                    # details: https://github.com/microformats/mf2py/issues/35\n                    microformat.update(simple_value)\n                else:\n                    microformat[\"value\"] = simple_value\n\n            if root_lang:\n                microformat[\"lang\"] = root_lang\n            elif self.lang:\n                microformat[\"lang\"] = self.lang\n            return microformat\n\n        def parse_props(el, root_lang):\n            \"\"\"Parse the properties from a single element\"\"\"\n            props = {}\n            children = []\n            # for processing implied properties: collects if property types (p, e, u, d(t)) or children (h) have been processed\n            parsed_types_aggregation = set()\n\n            classes = el.get(\"class\", [])\n            filtered_classes = mf2_classes.filter_classes(classes)\n            # Is this element a microformat2 root?\n            root_class_names = filtered_classes[\"h\"]\n            backcompat_mode = False\n\n            # Is this element a microformat1 root?\n            if not root_class_names:\n                root_class_names = backcompat.root(classes)\n                backcompat_mode = True\n\n            if root_class_names:\n                parsed_types_aggregation.add(\"h\")\n\n            # Is this a property element (p-*, u-*, etc.) flag\n            # False is default\n            is_property_el = False\n\n            # Parse plaintext p-* properties.\n            p_value = None\n            for prop_name in filtered_classes[\"p\"]:\n                is_property_el = True\n                parsed_types_aggregation.add(\"p\")\n                prop_value = props.setdefault(prop_name, [])\n\n                # if value has not been parsed then parse it\n                if p_value is None:\n                    p_value = parse_property.text(el, base_url=self.__url__)\n\n                if root_class_names:\n                    prop_value.append(\n                        handle_microformat(\n                            root_class_names,\n                            el,\n                            value_property=\"name\",\n                            simple_value=p_value,\n                            backcompat_mode=backcompat_mode,\n                        )\n                    )\n                else:\n                    prop_value.append(p_value)\n\n            # Parse URL u-* properties.\n            u_value = None\n            for prop_name in filtered_classes[\"u\"]:\n                is_property_el = True\n                parsed_types_aggregation.add(\"u\")\n                prop_value = props.setdefault(prop_name, [])\n\n                # if value has not been parsed then parse it\n                if u_value is None:\n                    u_value = parse_property.url(el, base_url=self.__url__)\n\n                if root_class_names:\n                    prop_value.append(\n                        handle_microformat(\n                            root_class_names,\n                            el,\n                            value_property=\"url\",\n                            simple_value=u_value,\n                            backcompat_mode=backcompat_mode,\n                        )\n                    )\n                else:\n                    if isinstance(u_value, dict):\n                        prop_value.append(u_value)\n                    else:\n                        prop_value.append(u_value)\n\n            # Parse datetime dt-* properties.\n            dt_value = None\n            for prop_name in filtered_classes[\"dt\"]:\n                is_property_el = True\n                parsed_types_aggregation.add(\"d\")\n                prop_value = props.setdefault(prop_name, [])\n\n                # if value has not been parsed then parse it\n                if dt_value is None:\n                    dt_value, new_date = parse_property.datetime(el, self._default_date)\n                    # update the default date\n                    if new_date:\n                        self._default_date = new_date\n\n                if root_class_names:\n                    stops_implied_name = True\n                    prop_value.append(\n                        handle_microformat(\n                            root_class_names,\n                            el,\n                            simple_value=dt_value,\n                            backcompat_mode=backcompat_mode,\n                        )\n                    )\n                else:\n                    if dt_value is not None:\n                        prop_value.append(dt_value)\n\n            # Parse embedded markup e-* properties.\n            e_value = None\n            for prop_name in filtered_classes[\"e\"]:\n                is_property_el = True\n                parsed_types_aggregation.add(\"e\")\n                prop_value = props.setdefault(prop_name, [])\n\n                # if value has not been parsed then parse it\n                if e_value is None:\n                    # send original element for parsing backcompat\n                    if el.original is None:\n                        embedded_el = el\n                    else:\n                        embedded_el = el.original\n                    if self._preserve_doc:\n                        embedded_el = copy.copy(embedded_el)\n                    temp_fixes.rm_templates(embedded_el)\n                    e_value = parse_property.embedded(\n                        embedded_el, self.__url__, root_lang, self.lang, self.expose_dom\n                    )\n\n                if root_class_names:\n                    stops_implied_name = True\n                    prop_value.append(\n                        handle_microformat(\n                            root_class_names,\n                            el,\n                            simple_value=e_value,\n                            backcompat_mode=backcompat_mode,\n                        )\n                    )\n                else:\n                    prop_value.append(e_value)\n\n            # if this is not a property element, but it is a h-* microformat,\n            # add it to our list of children\n            if not is_property_el and root_class_names:\n                children.append(\n                    handle_microformat(\n                        root_class_names, el, backcompat_mode=backcompat_mode\n                    )\n                )\n            # parse child tags, provided this isn't a microformat root-class\n            if not root_class_names:\n                for child in get_children(el):\n                    (\n                        child_properties,\n                        child_microformats,\n                        child_parsed_types_aggregation,\n                    ) = parse_props(child, root_lang)\n                    for prop_name in child_properties:\n                        v = props.get(prop_name, [])\n                        v.extend(child_properties[prop_name])\n                        props[prop_name] = v\n                    children.extend(child_microformats)\n                    parsed_types_aggregation.update(child_parsed_types_aggregation)\n            return props, children, parsed_types_aggregation\n\n        def parse_rels(el):\n            \"\"\"Parse an element for rel microformats\"\"\"\n            rel_attrs = get_attr(el, \"rel\")\n            # if rel attributes exist\n            if rel_attrs is not None:\n                # find the url and normalise it\n                url = try_urljoin(self.__url__, el.get(\"href\", \"\"))\n                value_dict = self.__parsed__[\"rel-urls\"].get(url, {})\n\n                # 1st one wins\n                if \"text\" not in value_dict:\n                    value_dict[\"text\"] = el.get_text().strip()\n\n                url_rels = value_dict.get(\"rels\", [])\n                value_dict[\"rels\"] = url_rels\n\n                for knownattr in (\"media\", \"hreflang\", \"type\", \"title\"):\n                    x = get_attr(el, knownattr)\n                    # 1st one wins\n                    if x is not None and knownattr not in value_dict:\n                        value_dict[knownattr] = x\n\n                self.__parsed__[\"rel-urls\"][url] = value_dict\n\n                for rel_value in rel_attrs:\n                    value_list = self.__parsed__[\"rels\"].get(rel_value, [])\n                    if url not in value_list:\n                        value_list.append(url)\n                    if rel_value not in url_rels:\n                        url_rels.append(rel_value)\n\n                    self.__parsed__[\"rels\"][rel_value] = value_list\n                if \"alternate\" in rel_attrs:\n                    alternate_list = self.__parsed__.get(\"alternates\", [])\n                    alternate_dict = {}\n                    alternate_dict[\"url\"] = url\n                    x = \" \".join([r for r in rel_attrs if not r == \"alternate\"])\n                    if x != \"\":\n                        alternate_dict[\"rel\"] = x\n                    alternate_dict[\"text\"] = el.get_text().strip()\n                    for knownattr in (\"media\", \"hreflang\", \"type\", \"title\"):\n                        x = get_attr(el, knownattr)\n                        if x is not None:\n                            alternate_dict[knownattr] = x\n                    alternate_list.append(alternate_dict)\n                    self.__parsed__[\"alternates\"] = alternate_list\n\n        def parse_el(el, ctx):\n            \"\"\"Parse an element for microformats\"\"\"\n            classes = el.get(\"class\", [])\n\n            # find potential microformats in root classnames h-*\n            potential_microformats = mf2_classes.root(classes, self.filtered_roots)\n\n            # if potential microformats found parse them\n            if potential_microformats:\n                result = handle_microformat(potential_microformats, el)\n                ctx.append(result)\n            else:\n                # find backcompat root classnames\n                potential_microformats = backcompat.root(classes)\n                if potential_microformats:\n                    result = handle_microformat(\n                        potential_microformats, el, backcompat_mode=True\n                    )\n                    ctx.append(result)\n                else:\n                    # parse child tags\n                    for child in get_children(el):\n                        parse_el(child, ctx)\n\n        ctx = []\n\n        if self.__metaformats:\n            # extract out a metaformats item, if available\n            self.__metaformats_item = metaformats.parse(self.__doc__, url=self.__url__)\n\n        # start parsing at root element of the document\n        parse_el(self.__doc__, ctx)\n        self.__parsed__[\"items\"] = ctx\n        if self.__metaformats and self.__metaformats_item:\n            self.__parsed__[\"items\"].append(self.__metaformats_item)\n\n        # parse for rel values\n        for el in get_descendents(self.__doc__):\n            if el.name in (\"a\", \"area\", \"link\") and el.has_attr(\"rel\"):\n                parse_rels(el)\n\n        # sort the rels array in rel-urls since this should be unordered set\n        for url in self.__parsed__[\"rel-urls\"]:\n            if \"rels\" in self.__parsed__[\"rel-urls\"][url]:\n                rels = self.__parsed__[\"rel-urls\"][url][\"rels\"]\n                self.__parsed__[\"rel-urls\"][url][\"rels\"] = unordered_list(rels)\n\n        # add actual parser used to debug\n        # uses builder.NAME from BeautifulSoup\n        if self.__html_parser__:\n            self.__parsed__[\"debug\"][\"markup parser\"] = self.__html_parser__\n        else:\n            self.__parsed__[\"debug\"][\"markup parser\"] = \"unknown\"\n\n    def to_dict(self, filter_by_type=None):\n        \"\"\"Get a dictionary version of the parsed microformat document.\n\n        Args:\n          filter_by_type (string, optional): only include top-level items of\n            the given h-* type. Defaults to None.\n\n        Returns:\n            dict: representation of the parsed microformats document\n        \"\"\"\n        if filter_by_type is None:\n            return self.__parsed__\n        else:\n            return [x for x in self.__parsed__[\"items\"] if filter_by_type in x[\"type\"]]\n\n    def to_json(self, pretty_print=False, filter_by_type=None):\n        \"\"\"Get a json-encoding string version of the parsed microformats document\n\n        Args:\n          pretty_print (bool, optional): Encode the json document with\n            linebreaks and indents to improve readability. Defaults to False.\n          filter_by_type (bool, optional): only include top-level items of\n            the given h-* type\n\n        Returns:\n            string: a json-encoded string\n        \"\"\"\n\n        if pretty_print:\n            return json.dumps(\n                self.to_dict(filter_by_type), indent=4, separators=(\", \", \": \")\n            )\n        else:\n            return json.dumps(self.to_dict(filter_by_type))\n</code></pre>"},{"location":"parser/#mf2py.Parser.to_dict","title":"<code>to_dict(filter_by_type=None)</code>","text":"<p>Get a dictionary version of the parsed microformat document.</p> <p>Parameters:</p> Name Type Description Default <code>filter_by_type</code> <code>string</code> <p>only include top-level items of the given h-* type. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>representation of the parsed microformats document</p> Source code in <code>mf2py/parser.py</code> <pre><code>def to_dict(self, filter_by_type=None):\n    \"\"\"Get a dictionary version of the parsed microformat document.\n\n    Args:\n      filter_by_type (string, optional): only include top-level items of\n        the given h-* type. Defaults to None.\n\n    Returns:\n        dict: representation of the parsed microformats document\n    \"\"\"\n    if filter_by_type is None:\n        return self.__parsed__\n    else:\n        return [x for x in self.__parsed__[\"items\"] if filter_by_type in x[\"type\"]]\n</code></pre>"},{"location":"parser/#mf2py.Parser.to_json","title":"<code>to_json(pretty_print=False, filter_by_type=None)</code>","text":"<p>Get a json-encoding string version of the parsed microformats document</p> <p>Parameters:</p> Name Type Description Default <code>pretty_print</code> <code>bool</code> <p>Encode the json document with linebreaks and indents to improve readability. Defaults to False.</p> <code>False</code> <code>filter_by_type</code> <code>bool</code> <p>only include top-level items of the given h-* type</p> <code>None</code> <p>Returns:</p> Name Type Description <code>string</code> <p>a json-encoded string</p> Source code in <code>mf2py/parser.py</code> <pre><code>def to_json(self, pretty_print=False, filter_by_type=None):\n    \"\"\"Get a json-encoding string version of the parsed microformats document\n\n    Args:\n      pretty_print (bool, optional): Encode the json document with\n        linebreaks and indents to improve readability. Defaults to False.\n      filter_by_type (bool, optional): only include top-level items of\n        the given h-* type\n\n    Returns:\n        string: a json-encoded string\n    \"\"\"\n\n    if pretty_print:\n        return json.dumps(\n            self.to_dict(filter_by_type), indent=4, separators=(\", \", \": \")\n        )\n    else:\n        return json.dumps(self.to_dict(filter_by_type))\n</code></pre>"}]}